{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a417d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"minGPT\")   # 让 mingpt 这个包可 import\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from minGPT.mingpt.model import GPT\n",
    "from minGPT.mingpt.utils import set_seed\n",
    "from minGPT.mingpt.bpe import BPETokenizer\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66067e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'gpt2'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = BPETokenizer()\n",
    "scaler = torch.cuda.amp.GradScaler() if device == 'cuda' else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1511554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 124.44M\n"
     ]
    }
   ],
   "source": [
    "# 调用minGPT\n",
    "# 如果要关掉记忆模块，令types=None即可\n",
    "model, _ = GPT.from_pretrained(model_type, types=\"nm\", model_dir=None)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30a93934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状： torch.Size([32, 1024])\n",
      "目标形状： torch.Size([32, 1024])\n",
      "prompt的类型 <class 'list'> 32\n",
      "prompt的第15个元素： Task: Reverse the string and remove vowels (a,e,i,o,u).\n",
      "Input: wcrwbjdqprjw\n",
      "Output:\n",
      "answer的类型 <class 'list'> 32\n",
      "answer的第15个元素： wjrpqdjbwrcw\n"
     ]
    }
   ],
   "source": [
    "from minGPT.mingpt.program_dataset import ProgramDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dynamic_cheatsheet import DynamicCheatsheetMemory\n",
    "from dynamic_cheatsheet.config_loader import load_config\n",
    "from dataclasses import asdict\n",
    "import random\n",
    "\n",
    "# 准备数据集\n",
    "train_dataset = ProgramDataset(\n",
    "    jsonl_path=\"./data_reverse_dropvowel/train.jsonl\",\n",
    "    block_size=1024,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 得到一个batch的数据\n",
    "def get_one_batch(dataset, batch_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    prompts = []\n",
    "    answers = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "        i = random.randrange(len(dataset))\n",
    "        idx, target, prompt, answer = dataset[i]\n",
    "        x.append(idx)\n",
    "        y.append(target)\n",
    "        prompts.append(prompt)\n",
    "        answers.append(answer)\n",
    "    \n",
    "    x = torch.stack(x, dim=0)\n",
    "    y = torch.stack(y, dim=0)\n",
    "    \n",
    "    return x, y, prompts, answers\n",
    "\n",
    "x, y, prompts, answers = get_one_batch(train_dataset, batch_size=32)\n",
    "\n",
    "print(\"输入形状：\", x.shape)\n",
    "print(\"目标形状：\", y.shape)\n",
    "print(\"prompt的类型\", type(prompts), len(prompts))\n",
    "print(\"prompt的第15个元素：\", prompts[15])\n",
    "print(\"answer的类型\", type(answers), len(answers))\n",
    "print(\"answer的第15个元素：\", answers[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33bdea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 8 1024\n",
      "dc_memory type: <class 'torch.Tensor'>\n",
      "dc_memory shape: torch.Size([32, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"dynamic_cheatsheet/config.yaml\")\n",
    "# hidden_dim 必须 = GPT 的 n_embd（gpt2 是 768）\n",
    "hidden_dim = model.transformer.wpe.embedding_dim\n",
    "dynamic_cheatsheet = DynamicCheatsheetMemory(asdict(cfg.dc), hidden_dim)\n",
    "print(hidden_dim, dynamic_cheatsheet.dc_len, dynamic_cheatsheet.embed_dim)\n",
    "\n",
    "dc_memory, _ = dynamic_cheatsheet.retrieve(prompts, batch_size=32, device=device)\n",
    "print(\"dc_memory type:\", type(dc_memory))\n",
    "print(\"dc_memory shape:\", dc_memory.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac453de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 结果评估函数\n",
    "import Levenshtein\n",
    "\n",
    "def exact_match(pred: str, gold: str) -> float:\n",
    "    return float(pred.strip() == gold.strip())\n",
    "\n",
    "def normalized_edit_similarity(pred: str, gold: str) -> float:\n",
    "    if len(gold) == 0:\n",
    "        return float(len(pred) == 0)\n",
    "\n",
    "    dist = Levenshtein.distance(pred, gold)\n",
    "    return 1.0 - dist / max(len(pred), len(gold))\n",
    "\n",
    "VOWELS = set(\"aeiouAEIOU\")\n",
    "\n",
    "def remove_vowels(s: str) -> str:\n",
    "    return \"\".join(c for c in s if c not in VOWELS)\n",
    "\n",
    "def reverse_string(s: str) -> str:\n",
    "    return s[::-1]\n",
    "\n",
    "def vowel_removal_accuracy(pred: str) -> float:\n",
    "    return float(all(c not in VOWELS for c in pred))\n",
    "\n",
    "def reverse_consistency(pred: str, gold: str) -> float:\n",
    "    return float(pred == gold[::-1])\n",
    "\n",
    "def evaluate_answer(pred: str, gold: str) -> dict:\n",
    "    pred = pred.strip()\n",
    "    gold = gold.strip()\n",
    "\n",
    "    metrics = {\n",
    "        \"exact_match\": exact_match(pred, gold),\n",
    "        \"edit_similarity\": normalized_edit_similarity(pred, gold),\n",
    "        \"no_vowel\": vowel_removal_accuracy(pred),\n",
    "        \"pred_len\": len(pred),\n",
    "        \"gold_len\": len(gold),\n",
    "        \"len_accuracy\": float(len(pred)) / len(gold) if len(gold) > 0 else 0.0,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def evaluate_batch(preds, golds):\n",
    "    all_metrics = []\n",
    "    for p, g in zip(preds, golds):\n",
    "        all_metrics.append(evaluate_answer(p, g))\n",
    "\n",
    "    # 求平均\n",
    "    avg = {}\n",
    "    for k in all_metrics[0]:\n",
    "        avg[k] = sum(m[k] for m in all_metrics) / len(all_metrics)\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4f3da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29072\\AppData\\Local\\Temp\\ipykernel_16768\\747282907.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\29072\\AppData\\Local\\Temp\\ipykernel_16768\\747282907.py:42: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估模式下，迭代 0，损失 4.9375\n",
      "迭代 0，评估指标: {'exact_match': 0.0, 'edit_similarity': 0.1477869467366842, 'no_vowel': 0.0, 'pred_len': 37.0, 'gold_len': 9.0}\n",
      "评估模式下，迭代 1，损失 5.9561\n",
      "迭代 1，评估指标: {'exact_match': 0.0, 'edit_similarity': 0.1337126600284495, 'no_vowel': 0.0, 'pred_len': 37.5, 'gold_len': 8.5}\n",
      "评估模式下，迭代 2，损失 5.5689\n",
      "迭代 2，评估指标: {'exact_match': 0.0, 'edit_similarity': 0.14756944444444442, 'no_vowel': 0.0, 'pred_len': 34.0, 'gold_len': 8.5}\n"
     ]
    }
   ],
   "source": [
    "# 冻结部分参数\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "if getattr(model, \"neural_memory\", None) is not None:\n",
    "    for p in model.neural_memory.parameters():\n",
    "        p.requires_grad = True\n",
    "if hasattr(model, \"dc_gate\"):\n",
    "    for p in model.dc_gate.parameters():\n",
    "        p.requires_grad = True\n",
    "if hasattr(model, \"nm_gate\"):\n",
    "    for p in model.nm_gate.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# 获取可训练参数及其名称\n",
    "trainable_params = [(n, p) for n, p in model.named_parameters() if p.requires_grad]\n",
    "\n",
    "# print(\"Trainable param groups:\")\n",
    "# for n, p in trainable_params:\n",
    "#     print(f\"  {n:60s} {p.numel()}\")\n",
    "# print(\"Total trainable:\", sum(p.numel() for _, p in trainable_params))\n",
    "\n",
    "# 只传递参数对象给优化器\n",
    "optimizer = torch.optim.AdamW([p for _, p in trainable_params], lr=3e-4)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "max_iters = 3\n",
    "batch_size = 2\n",
    "EOS_ID = 50256\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    x, y, prompts, answers = get_one_batch(train_dataset, batch_size=batch_size)\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dc_memory, _ = dynamic_cheatsheet.retrieve(prompts, batch_size=batch_size, device=device)\n",
    "    \n",
    "    model.train()\n",
    "    # logits, loss = model(x, y, dc_memory = dc_memory)\n",
    "    optimizer.zero_grad()\n",
    "    dc_memory = dc_memory.detach()\n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        logits, loss = model(x, y, dc_memory=dc_memory)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    \n",
    "    # 开启评估模式，生成文本并更新记忆\n",
    "    model.eval()\n",
    "    dc_update_str = \"\"\n",
    "    gen = []\n",
    "    for i in range(batch_size):\n",
    "        prompt_idx = tokenizer(prompts[i])[0].long().unsqueeze(0).to(device)\n",
    "        gen_ids = model.generate(\n",
    "            prompt_idx,\n",
    "            max_new_tokens=20,\n",
    "            temperature=1.0,\n",
    "            do_sample=False,\n",
    "            top_k=None,\n",
    "            dc_memory=dc_memory[i:i+1],\n",
    "            eos_token_id=EOS_ID,\n",
    "            return_only_generated=True,\n",
    "        )\n",
    "        gen_text = tokenizer.decode(gen_ids[0])\n",
    "        gen.append(gen_text)\n",
    "        # print(\"输入\", prompts[i])\n",
    "        # print(\"答案\", answers[i])\n",
    "        # print(\"生成文本\", gen_text)\n",
    "        dc_update_str += prompts[i] + \"\\n\" + answers[i] + \"\\n\" + \"GPT output:\" + gen_text + \"\\n\" \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dynamic_cheatsheet.update(dc_update_str, device=device)\n",
    "\n",
    "    # if iter % 100 == 0:\n",
    "    #     print(f\"评估模式下，迭代 {iter}，损失 {loss.item():.4f}\")\n",
    "    print(f\"评估模式下，迭代 {iter}，损失 {loss.item():.4f}\")\n",
    "    metrics = evaluate_batch(gen, answers)\n",
    "    print(f\"迭代 {iter}，评估指标: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dc280bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/embeddings/text-embedding/text-embedding (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[31mSSLError\u001b[39m: [SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/embeddings/text-embedding/text-embedding (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(test_size):\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         dc_memory, _ = \u001b[43mdynamic_cheatsheet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     dc_update_str = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m     prompt_idx = tokenizer(prompts[i])[\u001b[32m0\u001b[39m].long().unsqueeze(\u001b[32m0\u001b[39m).to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\vscode\\PRML\\PRML\\dynamic_cheatsheet\\cheatsheet_memory.py:204\u001b[39m, in \u001b[36mDynamicCheatsheetMemory.retrieve\u001b[39m\u001b[34m(self, query_texts, batch_size, device)\u001b[39m\n\u001b[32m    202\u001b[39m     q = \u001b[38;5;28mself\u001b[39m.embedder.embed_batch(query_texts, device=bank_device)  \u001b[38;5;66;03m# (B,D)\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     q_list = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbank_device\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m query_texts]\n\u001b[32m    205\u001b[39m     q = torch.stack(q_list, dim=\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# (B,D)\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# 关键：强制对齐 dtype/device\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\vscode\\PRML\\PRML\\dynamic_cheatsheet\\embed_client.py:41\u001b[39m, in \u001b[36mEmbedClient.embed\u001b[39m\u001b[34m(self, text, device)\u001b[39m\n\u001b[32m     38\u001b[39m text = (text \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.provider == \u001b[33m\"\u001b[39m\u001b[33mqwen\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_qwen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# default: stub hashing\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_stub(text, device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\vscode\\PRML\\PRML\\dynamic_cheatsheet\\embed_client.py:68\u001b[39m, in \u001b[36mEmbedClient._embed_qwen\u001b[39m\u001b[34m(self, text, device)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m text:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.zeros(\u001b[38;5;28mself\u001b[39m.embed_dim, device=device)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m resp = \u001b[43mTextEmbedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# e.g. \"text-embedding-v3\"\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# 兼容不同 SDK 返回结构\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\dashscope\\embeddings\\text_embedding.py:49\u001b[39m, in \u001b[36mTextEmbedding.call\u001b[39m\u001b[34m(cls, model, input, workspace, api_key, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# not support streaming output.\u001b[39;00m\n\u001b[32m     48\u001b[39m task_group, function = _get_task_group_and_task(\u001b[34m__name__\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43membedding_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtask_group\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTextEmbedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\dashscope\\client\\base_api.py:440\u001b[39m, in \u001b[36mBaseApi.call\u001b[39m\u001b[34m(cls, model, input, task_group, task, function, api_key, workspace, **kwargs)\u001b[39m\n\u001b[32m    432\u001b[39m request = _build_api_request(model=model,\n\u001b[32m    433\u001b[39m                              \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m,\n\u001b[32m    434\u001b[39m                              task_group=task_group,\n\u001b[32m   (...)\u001b[39m\u001b[32m    437\u001b[39m                              api_key=api_key,\n\u001b[32m    438\u001b[39m                              **kwargs)\n\u001b[32m    439\u001b[39m \u001b[38;5;66;03m# call request service.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\dashscope\\api_entities\\http_request.py:106\u001b[39m, in \u001b[36mHttpRequest.call\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     output = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;28mnext\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\dashscope\\api_entities\\http_request.py:379\u001b[39m, in \u001b[36mHttpRequest._handle_request\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    378\u001b[39m     logger.error(e)\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\dashscope\\api_entities\\http_request.py:362\u001b[39m, in \u001b[36mHttpRequest._handle_request\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         logger.debug(\u001b[33m'\u001b[39m\u001b[33mRequest body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % obj)\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method == HTTPMethod.GET:\n\u001b[32m    368\u001b[39m     response = session.get(url=\u001b[38;5;28mself\u001b[39m.url,\n\u001b[32m    369\u001b[39m                            params=\u001b[38;5;28mself\u001b[39m.data.parameters,\n\u001b[32m    370\u001b[39m                            headers=\u001b[38;5;28mself\u001b[39m.headers,\n\u001b[32m    371\u001b[39m                            timeout=\u001b[38;5;28mself\u001b[39m.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\requests\\sessions.py:637\u001b[39m, in \u001b[36mSession.post\u001b[39m\u001b[34m(self, url, data, json, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\29072\\anaconda3\\envs\\test\\Lib\\site-packages\\requests\\adapters.py:698\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    694\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request=request)\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mSSLError\u001b[39m: HTTPSConnectionPool(host='dashscope.aliyuncs.com', port=443): Max retries exceeded with url: /api/v1/services/embeddings/text-embedding/text-embedding (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)')))"
     ]
    }
   ],
   "source": [
    "model.eval();\n",
    "\n",
    "# 准备数据集\n",
    "test_dataset = ProgramDataset(\n",
    "    jsonl_path=\"./data_reverse_dropvowel/test.jsonl\",\n",
    "    block_size=1024,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# 得到一个batch的数据\n",
    "test_size = 100\n",
    "x, y, prompts, answers = get_one_batch(test_dataset, batch_size=test_size)\n",
    "gen = []\n",
    "\n",
    "for i in range(test_size):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dc_memory, _ = dynamic_cheatsheet.retrieve([prompts[i]], batch_size=1, device=device)\n",
    "    dc_update_str = \"\"\n",
    "    prompt_idx = tokenizer(prompts[i])[0].long().unsqueeze(0).to(device)\n",
    "    gen_ids = model.generate(\n",
    "        prompt_idx,\n",
    "        max_new_tokens=20,\n",
    "        temperature=1.0,\n",
    "        do_sample=False,\n",
    "        top_k=None,\n",
    "        dc_memory=dc_memory,\n",
    "        eos_token_id=EOS_ID,\n",
    "        return_only_generated=True,\n",
    "    )\n",
    "    gen_text = tokenizer.decode(gen_ids[0])\n",
    "    gen.append(gen_text)\n",
    "    dc_update_str += prompts[i] + \"\\n\" + answers[i] + \"\\n\" + \"GPT output:\" + gen_text + \"\\n\" \n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            dynamic_cheatsheet.update(dc_update_str, device=device)\n",
    "\n",
    "\n",
    "metrics = evaluate_batch(gen, answers)\n",
    "print(f\"test评估指标: {metrics}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
